{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "2Hkzdvypm_0m"
   },
   "outputs": [],
   "source": [
    "from proj1_helpers import load_csv_data, predict_labels, create_csv_submission\n",
    "#import created_helpers as ch\n",
    "import numpy as np\n",
    "import random\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "VhhwppgKoHyE"
   },
   "outputs": [],
   "source": [
    "data_path = './'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "RLUZgUMcoKle"
   },
   "outputs": [],
   "source": [
    "train_data_path = os.path.join(data_path, \"train.csv\")\n",
    "test_data_path = os.path.join(data_path,\"test.csv\")\n",
    "\n",
    "y_train, x_train, ids_train = load_csv_data(train_data_path)\n",
    "y_test, x_test, ids_test = load_csv_data(test_data_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "7FnzLamKoMkg",
    "outputId": "073606e8-6516-47b3-9660-a7abf91991a2",
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>DER_mass_MMC</th>\n",
       "      <th>DER_mass_transverse_met_lep</th>\n",
       "      <th>DER_mass_vis</th>\n",
       "      <th>DER_pt_h</th>\n",
       "      <th>DER_deltaeta_jet_jet</th>\n",
       "      <th>DER_mass_jet_jet</th>\n",
       "      <th>DER_prodeta_jet_jet</th>\n",
       "      <th>DER_deltar_tau_lep</th>\n",
       "      <th>DER_pt_tot</th>\n",
       "      <th>...</th>\n",
       "      <th>PRI_met_phi</th>\n",
       "      <th>PRI_met_sumet</th>\n",
       "      <th>PRI_jet_num</th>\n",
       "      <th>PRI_jet_leading_pt</th>\n",
       "      <th>PRI_jet_leading_eta</th>\n",
       "      <th>PRI_jet_leading_phi</th>\n",
       "      <th>PRI_jet_subleading_pt</th>\n",
       "      <th>PRI_jet_subleading_eta</th>\n",
       "      <th>PRI_jet_subleading_phi</th>\n",
       "      <th>PRI_jet_all_pt</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "      <td>250000.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>224999.500000</td>\n",
       "      <td>-49.023079</td>\n",
       "      <td>49.239819</td>\n",
       "      <td>81.181982</td>\n",
       "      <td>57.895962</td>\n",
       "      <td>-708.420675</td>\n",
       "      <td>-601.237051</td>\n",
       "      <td>-709.356603</td>\n",
       "      <td>2.373100</td>\n",
       "      <td>18.917332</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.010119</td>\n",
       "      <td>209.797178</td>\n",
       "      <td>0.979176</td>\n",
       "      <td>-348.329567</td>\n",
       "      <td>-399.254314</td>\n",
       "      <td>-399.259788</td>\n",
       "      <td>-692.381204</td>\n",
       "      <td>-709.121609</td>\n",
       "      <td>-709.118631</td>\n",
       "      <td>73.064591</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>72168.927986</td>\n",
       "      <td>406.345647</td>\n",
       "      <td>35.344886</td>\n",
       "      <td>40.828691</td>\n",
       "      <td>63.655682</td>\n",
       "      <td>454.480565</td>\n",
       "      <td>657.972302</td>\n",
       "      <td>453.019877</td>\n",
       "      <td>0.782911</td>\n",
       "      <td>22.273494</td>\n",
       "      <td>...</td>\n",
       "      <td>1.812223</td>\n",
       "      <td>126.499506</td>\n",
       "      <td>0.977426</td>\n",
       "      <td>532.962789</td>\n",
       "      <td>489.338286</td>\n",
       "      <td>489.333883</td>\n",
       "      <td>479.875496</td>\n",
       "      <td>453.384624</td>\n",
       "      <td>453.389017</td>\n",
       "      <td>98.015662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>100000.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>6.329000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.208000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>-3.142000</td>\n",
       "      <td>13.678000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>162499.750000</td>\n",
       "      <td>78.100750</td>\n",
       "      <td>19.241000</td>\n",
       "      <td>59.388750</td>\n",
       "      <td>14.068750</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>1.810000</td>\n",
       "      <td>2.841000</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.575000</td>\n",
       "      <td>123.017500</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>224999.500000</td>\n",
       "      <td>105.012000</td>\n",
       "      <td>46.524000</td>\n",
       "      <td>73.752000</td>\n",
       "      <td>38.467500</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>2.491500</td>\n",
       "      <td>12.315500</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.024000</td>\n",
       "      <td>179.739000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>38.960000</td>\n",
       "      <td>-1.872000</td>\n",
       "      <td>-2.093000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>-999.000000</td>\n",
       "      <td>40.512500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>287499.250000</td>\n",
       "      <td>130.606250</td>\n",
       "      <td>73.598000</td>\n",
       "      <td>92.259000</td>\n",
       "      <td>79.169000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>83.446000</td>\n",
       "      <td>-4.593000</td>\n",
       "      <td>2.961000</td>\n",
       "      <td>27.591000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.561000</td>\n",
       "      <td>263.379250</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>75.349000</td>\n",
       "      <td>0.433000</td>\n",
       "      <td>0.503000</td>\n",
       "      <td>33.703000</td>\n",
       "      <td>-2.457000</td>\n",
       "      <td>-2.275000</td>\n",
       "      <td>109.933750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>349999.000000</td>\n",
       "      <td>1192.026000</td>\n",
       "      <td>690.075000</td>\n",
       "      <td>1349.351000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>8.503000</td>\n",
       "      <td>4974.979000</td>\n",
       "      <td>16.690000</td>\n",
       "      <td>5.684000</td>\n",
       "      <td>2834.999000</td>\n",
       "      <td>...</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>2003.976000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1120.573000</td>\n",
       "      <td>4.499000</td>\n",
       "      <td>3.141000</td>\n",
       "      <td>721.456000</td>\n",
       "      <td>4.500000</td>\n",
       "      <td>3.142000</td>\n",
       "      <td>1633.433000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 31 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Id   DER_mass_MMC  DER_mass_transverse_met_lep  \\\n",
       "count  250000.000000  250000.000000                250000.000000   \n",
       "mean   224999.500000     -49.023079                    49.239819   \n",
       "std     72168.927986     406.345647                    35.344886   \n",
       "min    100000.000000    -999.000000                     0.000000   \n",
       "25%    162499.750000      78.100750                    19.241000   \n",
       "50%    224999.500000     105.012000                    46.524000   \n",
       "75%    287499.250000     130.606250                    73.598000   \n",
       "max    349999.000000    1192.026000                   690.075000   \n",
       "\n",
       "        DER_mass_vis       DER_pt_h  DER_deltaeta_jet_jet  DER_mass_jet_jet  \\\n",
       "count  250000.000000  250000.000000         250000.000000     250000.000000   \n",
       "mean       81.181982      57.895962           -708.420675       -601.237051   \n",
       "std        40.828691      63.655682            454.480565        657.972302   \n",
       "min         6.329000       0.000000           -999.000000       -999.000000   \n",
       "25%        59.388750      14.068750           -999.000000       -999.000000   \n",
       "50%        73.752000      38.467500           -999.000000       -999.000000   \n",
       "75%        92.259000      79.169000              0.490000         83.446000   \n",
       "max      1349.351000    2834.999000              8.503000       4974.979000   \n",
       "\n",
       "       DER_prodeta_jet_jet  DER_deltar_tau_lep     DER_pt_tot       ...        \\\n",
       "count        250000.000000       250000.000000  250000.000000       ...         \n",
       "mean           -709.356603            2.373100      18.917332       ...         \n",
       "std             453.019877            0.782911      22.273494       ...         \n",
       "min            -999.000000            0.208000       0.000000       ...         \n",
       "25%            -999.000000            1.810000       2.841000       ...         \n",
       "50%            -999.000000            2.491500      12.315500       ...         \n",
       "75%              -4.593000            2.961000      27.591000       ...         \n",
       "max              16.690000            5.684000    2834.999000       ...         \n",
       "\n",
       "         PRI_met_phi  PRI_met_sumet    PRI_jet_num  PRI_jet_leading_pt  \\\n",
       "count  250000.000000  250000.000000  250000.000000       250000.000000   \n",
       "mean       -0.010119     209.797178       0.979176         -348.329567   \n",
       "std         1.812223     126.499506       0.977426          532.962789   \n",
       "min        -3.142000      13.678000       0.000000         -999.000000   \n",
       "25%        -1.575000     123.017500       0.000000         -999.000000   \n",
       "50%        -0.024000     179.739000       1.000000           38.960000   \n",
       "75%         1.561000     263.379250       2.000000           75.349000   \n",
       "max         3.142000    2003.976000       3.000000         1120.573000   \n",
       "\n",
       "       PRI_jet_leading_eta  PRI_jet_leading_phi  PRI_jet_subleading_pt  \\\n",
       "count        250000.000000        250000.000000          250000.000000   \n",
       "mean           -399.254314          -399.259788            -692.381204   \n",
       "std             489.338286           489.333883             479.875496   \n",
       "min            -999.000000          -999.000000            -999.000000   \n",
       "25%            -999.000000          -999.000000            -999.000000   \n",
       "50%              -1.872000            -2.093000            -999.000000   \n",
       "75%               0.433000             0.503000              33.703000   \n",
       "max               4.499000             3.141000             721.456000   \n",
       "\n",
       "       PRI_jet_subleading_eta  PRI_jet_subleading_phi  PRI_jet_all_pt  \n",
       "count           250000.000000           250000.000000   250000.000000  \n",
       "mean              -709.121609             -709.118631       73.064591  \n",
       "std                453.384624              453.389017       98.015662  \n",
       "min               -999.000000             -999.000000        0.000000  \n",
       "25%               -999.000000             -999.000000        0.000000  \n",
       "50%               -999.000000             -999.000000       40.512500  \n",
       "75%                 -2.457000               -2.275000      109.933750  \n",
       "max                  4.500000                3.142000     1633.433000  \n",
       "\n",
       "[8 rows x 31 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "data_train = pd.read_csv(train_data_path)\n",
    "data_test = pd.read_csv(test_data_path)\n",
    "data_train.head()\n",
    "data_train.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def standardize(x):\n",
    "    ''' fill your code in here...\n",
    "    '''\n",
    "    centered_data = x - np.mean(x, axis=0)\n",
    "    std_data = centered_data / np.std(centered_data, axis=0)\n",
    "    \n",
    "    return std_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train[y_train == -1] = 0\n",
    "x_train_s = standardize(x_train)\n",
    "x_train_sd = np.insert(x_train_s,0,1,axis=1)\n",
    "\n",
    "x_test_s = standardize(x_test)\n",
    "x_test_sd = np.insert(x_test_s,0,1,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 68
    },
    "colab_type": "code",
    "id": "3SC5_MDmZAh6",
    "outputId": "7a081665-24c6-4650-9582-d7fec98fb14b"
   },
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "initial_gamma = 1\n",
    "n = x_train_sd.shape[1]\n",
    "m = x_train_sd.shape[0]\n",
    "initial_w = np.array([0] * n)\n",
    "max_iters = 1500\n",
    "\n",
    "def sigmoid_fn(z):\n",
    "    #print(z)\n",
    "    h = 1 / (1 + np.exp(-z))\n",
    "    return h\n",
    "\n",
    "def logistic_regression_cost(y, tx, w):\n",
    "    #print(\"w: \", w)\n",
    "    z = tx.dot(w)\n",
    "    #print(\"z: \", z)\n",
    "    h = sigmoid_fn(z)\n",
    "    #print(\"h: \", h)\n",
    "    #print(\"np.log: \", np.log(h))\n",
    "    first_term = -y.T.dot(np.log(h))\n",
    "    #print(\"first term: \", first_term)\n",
    "    second_term = (1 - y).T.dot(np.log(1 - h))\n",
    "    #print(\"second term: \", second_term)\n",
    "    cost = (-y.T.dot(np.log(h)) - (1 - y).T.dot(np.log(1 - h))) / m\n",
    "    #print(\"cost: \", cost)\n",
    "    #print()\n",
    "    return cost\n",
    "\n",
    "def logistic_regression_gradient(y, tx, w):\n",
    "    z = tx.dot(w) # m,n x n,1 -> m,1\n",
    "    h = sigmoid_fn(z)\n",
    "    grad = tx.T.dot(h - y) / m\n",
    "    return grad\n",
    "\n",
    "def logistic_regression_gradient_descent(y, tx, w, max_iters, gamma):\n",
    "    # start the logistic regression\n",
    "    J_history =[]\n",
    "    for i in range(max_iters):\n",
    "        loss = logistic_regression_cost(y, tx, w)\n",
    "        grad = logistic_regression_gradient(y, tx, w)\n",
    "        w = w - gamma * grad\n",
    "        J_history.append(loss)\n",
    "    #return w, loss\n",
    "    print(w)\n",
    "    return w, J_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "3287eb0W4eEF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-9.11170177e-01  2.18721488e-01 -6.53827211e-01 -1.07972392e+00\n",
      "  2.19434286e-01 -1.11539738e-01  1.44949002e+00 -1.55117420e-01\n",
      "  1.03243740e+00 -3.29534072e-03 -3.59433205e-02 -7.62990256e-01\n",
      "  2.29139822e-01 -1.10813002e-01  5.50795078e-01 -1.56791098e-03\n",
      " -2.14699361e-03  1.04373010e+00 -2.52336949e-03  7.11057934e-03\n",
      "  2.37573371e-01  1.03321692e-03 -2.01184651e-01 -4.68788643e-01\n",
      "  1.35241636e-01  1.53506479e-01  1.53017483e-01 -1.29304723e-01\n",
      " -1.25003820e-01 -1.31102041e-01 -4.03330949e-01]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "optimal_weight, J_history = logistic_regression_gradient_descent(y_train, x_train_sd, initial_w, max_iters, initial_gamma)\n",
    "\n",
    "plt.plot(np.arange(max_iters), J_history, 'r') \n",
    "# better to use arange than linspace when dealing with integer interval steps \n",
    "\n",
    "plt.xlabel('# of iterations')\n",
    "plt.ylabel('cost value')\n",
    "plt.show()\n",
    "#create_csv_submission(ids_test, y_pred,'logistic_regression' + str(datetime.now()) + '.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_probs(w, X):\n",
    "    return sigmoid_fn(np.dot(X, w))\n",
    "\n",
    "def predict(w, X, threshold=0.5):\n",
    "    y_pred = predict_probs(w, X)\n",
    "    y_pred[np.where(y_pred < threshold)] = -1\n",
    "    y_pred[np.where(y_pred >= threshold)] = 1\n",
    "    return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1., -1., -1., ...,  1.,  1., -1.])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = predict(optimal_weight, x_test_sd)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 677
    },
    "colab_type": "code",
    "id": "sY6fikSs3Aln",
    "outputId": "f6a7aefd-42c0-4dd3-aa86-884b17ef3ab5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.25697858995702505\n",
      "0.122928\n"
     ]
    }
   ],
   "source": [
    "def accuracy(y_pred, y):\n",
    "    assert len(y_pred) == len(y)\n",
    "    correct = 0\n",
    "    for i in range(len(y_pred)):\n",
    "        if y_pred[i] == y[i]:\n",
    "            correct += 1\n",
    "    return correct / len(y)\n",
    "\n",
    "x_test_sdd = np.insert(x_test,0,1,axis=1)\n",
    "y_pred = predict(optimal_weight, x_test_sdd)       \n",
    "print(accuracy(y_pred, y_test))\n",
    "\n",
    "x_train_sdd = np.insert(x_train,0,1,axis=1)\n",
    "y_pred = predict(optimal_weight, x_train_sdd)       \n",
    "print(accuracy(y_pred, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-1387.16822396,  -765.97986276, -1183.02306264, ...,\n",
       "       -1157.7158591 ,  -739.41090234, -1189.71216396])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_test_sdd.dot(optimal_weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def reg_logistic_regression_cost_grad(y, tx, w, lambda_):\n",
    "    loss = logistic_regression_cost(y, tx, w) + lambda_ * np.squeeze(w.T.dot(w))\n",
    "    gradient = logistic_regression_gradient(y, tx, w) + 2 * lambda_ * w\n",
    "    return loss, gradient\n",
    "\n",
    "def reg_logistic_gradient(y, tx, w, gamma, lambda_):\n",
    "    \"\"\"\n",
    "    Do one step of gradient descent, using the penalized logistic regression.\n",
    "    Return the loss and updated w.\n",
    "    \"\"\"\n",
    "    loss, gradient = reg_logistic_regression_cost_grad(y, tx, w, lambda_)\n",
    "    w = w - gamma * gradient\n",
    "    return loss, w\n",
    "  \n",
    "def reg_logistic_regression(y, tx, lambda_,initial_w, max_iters, gamma):\n",
    "    for i in range(max_iters):\n",
    "        if (i > 0):\n",
    "            gamma = 1 / i\n",
    "        for minibatch_y, minibatch_tx in batch_iter(y, tx, 1): # O(1) runtime\n",
    "            loss, initial_w = reg_logistic_gradient (minibatch_y, minibatch_tx, initial_w, gamma, lambda_)\n",
    "    return initial_w, loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_test),2500):\n",
    "    print(y_test[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(y_train),2500):\n",
    "    print(y_train[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Kaggle1_beaver.ipynb",
   "provenance": [],
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
